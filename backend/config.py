# config.py

# CHANGE THIS ONE LINE to switch models everywhere
# Recommended for RTX 4070 (12GB VRAM): "llama3.1" or "deepseek-r1:7b"
OLLAMA_MODEL = "MedAIBase/MedGemma1.5:4b" 

# Global Settings
TEMPERATURE = 0.1
BASE_URL = "http://localhost:11434"